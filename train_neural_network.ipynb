{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LOTL Detection - Neural Network Training\n",
        "\n",
        "This notebook trains a small neural network for LOTL attack detection.\n",
        "Run this on Google Colab for GPU acceleration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch sentence-transformers scikit-learn numpy pandas\n",
        "\n",
        "# Upload dataset.jsonl to Colab\n",
        "# Use the file uploader or mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from pathlib import Path\n",
        "\n",
        "# Import our modules (upload these files to Colab or use from GitHub)\n",
        "from feature_extractor import ComprehensiveFeatureExtractor\n",
        "from data_loader import load_dataset, filter_label_agreement, get_labels, split_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "events = load_dataset('dataset.jsonl')\n",
        "print(f\"Loaded {len(events)} events\")\n",
        "\n",
        "# Filter events where Claude and ground truth agree\n",
        "filtered_events, _ = filter_label_agreement(events)\n",
        "print(f\"Kept {len(filtered_events)} events with agreement\")\n",
        "\n",
        "# Get labels\n",
        "labels = get_labels(filtered_events, use_claude_label=True)\n",
        "\n",
        "# Split dataset\n",
        "train_events, test_events, train_indices, test_indices = split_dataset(\n",
        "    filtered_events, test_size=0.2, random_seed=42\n",
        ")\n",
        "\n",
        "train_labels = [labels[i] for i in train_indices]\n",
        "test_labels = [labels[i] for i in test_indices]\n",
        "\n",
        "print(f\"Training: {len(train_events)} events\")\n",
        "print(f\"Test: {len(test_events)} events\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize feature extractor\n",
        "feature_extractor = ComprehensiveFeatureExtractor(use_text_embeddings=True)\n",
        "\n",
        "# Extract features for training set\n",
        "print(\"Extracting training features...\")\n",
        "train_features = []\n",
        "for event in train_events:\n",
        "    features = feature_extractor.extract_all_features(event)\n",
        "    train_features.append(features)\n",
        "\n",
        "# Extract features for test set\n",
        "print(\"Extracting test features...\")\n",
        "test_features = []\n",
        "for event in test_events:\n",
        "    features = feature_extractor.extract_all_features(event)\n",
        "    test_features.append(features)\n",
        "\n",
        "# Get feature names\n",
        "feature_names = sorted(train_features[0].keys())\n",
        "print(f\"Number of features: {len(feature_names)}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = np.array([[f.get(name, 0) for name in feature_names] for f in train_features])\n",
        "X_test = np.array([[f.get(name, 0) for name in feature_names] for f in test_features])\n",
        "\n",
        "print(f\"Training shape: {X_train.shape}\")\n",
        "print(f\"Test shape: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LOTLNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims=[128, 64], dropout=0.3):\n",
        "        super(LOTLNet, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        \n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            prev_dim = hidden_dim\n",
        "        \n",
        "        # Output layer (binary classification)\n",
        "        layers.append(nn.Linear(prev_dim, 2))\n",
        "        \n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X_train.shape[1]\n",
        "model = LOTLNet(input_dim=input_dim, hidden_dims=[128, 64], dropout=0.3)\n",
        "print(f\"Model initialized with input_dim={input_dim}\")\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Data for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(train_labels)\n",
        "y_test_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
        "y_train_tensor = torch.LongTensor(y_train_encoded)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
        "y_test_tensor = torch.LongTensor(y_test_encoded)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Training batches: {len(train_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 50\n",
        "best_f1 = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "    \n",
        "    # Evaluation\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "            \n",
        "            for batch_X, batch_y in test_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                outputs = model(batch_X)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(batch_y.numpy())\n",
        "            \n",
        "            # Calculate metrics\n",
        "            y_pred = label_encoder.inverse_transform(all_preds)\n",
        "            y_true = label_encoder.inverse_transform(all_labels)\n",
        "            \n",
        "            acc = accuracy_score(y_true, y_pred)\n",
        "            prec = precision_score(y_true, y_pred, pos_label='malicious', zero_division=0)\n",
        "            rec = recall_score(y_true, y_pred, pos_label='malicious', zero_division=0)\n",
        "            f1 = f1_score(y_true, y_pred, pos_label='malicious', zero_division=0)\n",
        "            \n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                # Save best model\n",
        "                torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'input_dim': input_dim,\n",
        "                    'hidden_dims': [128, 64],\n",
        "                    'dropout': 0.3,\n",
        "                    'scaler': scaler,\n",
        "                    'label_encoder': label_encoder,\n",
        "                    'feature_names': feature_names\n",
        "                }, 'best_model.pt')\n",
        "            \n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, \"\n",
        "                  f\"Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining complete! Best F1: {best_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "checkpoint = torch.load('best_model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Evaluate on test set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        outputs = model(batch_X)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_y.numpy())\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "y_pred = label_encoder.inverse_transform(all_preds)\n",
        "y_true = label_encoder.inverse_transform(all_labels)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Final Test Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred, pos_label='malicious', zero_division=0):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred, pos_label='malicious', zero_division=0):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label='malicious', zero_division=0):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the model file\n",
        "from google.colab import files\n",
        "files.download('best_model.pt')\n",
        "\n",
        "print(\"Model downloaded! Place it in the models/ directory of your project.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
